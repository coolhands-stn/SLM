{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VDZl9nurWAYs"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Ndakaona kuti ndaitopedza nguva\n",
        "ndakagara nguva ichifamba. Ndakabva\n",
        "ndatosimuka very fast ndaida kuona\n",
        "musikana wepanext wayimboita nyaya\n",
        "naRue. Ndiye munhu chaiye aigona\n",
        "kundibatsira. Ndakabva ndafunga maUSD\n",
        "aVanessa aayitenga hanzi hee ndakuda\n",
        "kutengawo kaHonda fit kangu.\n",
        "Ndaitomupawo mamwe maZim dollar ekutenga maUSD acho. Kutaura chokwadi\n",
        "Vanessa ndaimuda hangu imhepo\n",
        "dzaingondibatawo. She was wife material\n",
        "and very responsible. Ndakatora mari Iya ndikaiverenga. Inga\n",
        "\n",
        "yakanga yawanda mari yemukadzi wangu.\n",
        "Panga pava ne1900. Ndakanatsobisa 1000\n",
        "yose ndikaisa muhomwe\n",
        "ndaitonoichengetesa shamwari yangu.\n",
        "Rue ndiye aifanira kutoisafira mari iyoyo.\n",
        "Ndakazobisawo kamwe ka20 kuti ndigopa\n",
        "musikana uya wepanext tichironga dhiri\n",
        "redu. Ndichibuda panze ndakaita\n",
        "lucky ndichiwanawo ari panze. Iyewo\n",
        "anenge ayitovawo necrush neni.\n",
        "Ndakamupa sign yekuti auye pandaiva.\n",
        "Akatanga aringa ringa maside ose\n",
        "achibva anyahwaira achiuya. Handina'''"
      ],
      "metadata": {
        "id": "uRQLl2R4WOQ5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded_data = tokenizer.texts_to_sequences([text])[0]\n",
        "vocabulary_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "9l4PrRMaWT3O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the tokenizer object for future use\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "5nV3yMmTWga9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(1, len(encoded_data)):\n",
        "    sequence = encoded_data[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=6, padding='pre'))\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=vocabulary_size)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "fYv6Q98aWkUB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "zgTYOEpsYWls"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating word embeddings\n",
        "sentences = [sentence.split() for sentence in text.split('.')]\n",
        "model_gensim = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "model_gensim.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "fK7ty_RnYL64"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gensim = Word2Vec.load(\"word2vec.model\")\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    try:\n",
        "        embedding_vector = model_gensim.wv[word]\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    except KeyError:\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "RXUSiFhyYa03"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(vocabulary_size, 100, input_length=5),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.LSTM(100),\n",
        "  tf.keras.layers.Dense(vocabulary_size, activation='softmax')\n",
        "])\n",
        "\n",
        "first_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oHeBauLEYsWz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(vocabulary_size, 100, weights=[embedding_matrix], input_length=5, trainable=False),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.LSTM(100),\n",
        "  tf.keras.layers.Dense(vocabulary_size, activation='softmax')\n",
        "])\n",
        "\n",
        "second_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "l8erw5UWZ4yG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model 1\n",
        "first_history = first_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, verbose=1)\n",
        "\n",
        "# Training Model 2\n",
        "second_history = second_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ0h3_fpai-2",
        "outputId": "65869ae0-db5b-41f0-9956-7e8a11be458e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 8s 858ms/step - loss: 4.7016 - accuracy: 0.0000e+00 - val_loss: 4.7026 - val_accuracy: 0.0208\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 4.6925 - accuracy: 0.1408 - val_loss: 4.7055 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 4.6850 - accuracy: 0.2535 - val_loss: 4.7090 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.6765 - accuracy: 0.1972 - val_loss: 4.7135 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 4.6669 - accuracy: 0.1831 - val_loss: 4.7194 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 4.6546 - accuracy: 0.1268 - val_loss: 4.7278 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 4.6385 - accuracy: 0.1408 - val_loss: 4.7403 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 4.6159 - accuracy: 0.1127 - val_loss: 4.7607 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 4.5819 - accuracy: 0.0704 - val_loss: 4.7985 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 4.5286 - accuracy: 0.0423 - val_loss: 4.8788 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 4.4434 - accuracy: 0.0282 - val_loss: 5.0665 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 4.3163 - accuracy: 0.0141 - val_loss: 5.4785 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 4.2036 - accuracy: 0.0141 - val_loss: 5.9453 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 4.1143 - accuracy: 0.0282 - val_loss: 6.0330 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 3.9887 - accuracy: 0.0563 - val_loss: 5.9987 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 3.8433 - accuracy: 0.0423 - val_loss: 5.9641 - val_accuracy: 0.0208\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.6701 - accuracy: 0.1408 - val_loss: 6.0624 - val_accuracy: 0.0208\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.5015 - accuracy: 0.1690 - val_loss: 6.2980 - val_accuracy: 0.0208\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.3097 - accuracy: 0.2254 - val_loss: 6.6074 - val_accuracy: 0.0208\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 3.0717 - accuracy: 0.2676 - val_loss: 6.8634 - val_accuracy: 0.0208\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.8427 - accuracy: 0.2676 - val_loss: 7.0550 - val_accuracy: 0.0208\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.6638 - accuracy: 0.2958 - val_loss: 7.1926 - val_accuracy: 0.0208\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.4650 - accuracy: 0.3521 - val_loss: 7.3574 - val_accuracy: 0.0208\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.3082 - accuracy: 0.4507 - val_loss: 7.3606 - val_accuracy: 0.0208\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.1094 - accuracy: 0.5352 - val_loss: 7.3960 - val_accuracy: 0.0208\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.9591 - accuracy: 0.5070 - val_loss: 7.5585 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.8144 - accuracy: 0.5915 - val_loss: 7.8055 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.6751 - accuracy: 0.6620 - val_loss: 7.9073 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.5877 - accuracy: 0.6479 - val_loss: 7.8746 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 1.4375 - accuracy: 0.7324 - val_loss: 7.9196 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.3615 - accuracy: 0.7606 - val_loss: 7.9850 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.2656 - accuracy: 0.7887 - val_loss: 8.0685 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.2110 - accuracy: 0.7746 - val_loss: 8.1672 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.1261 - accuracy: 0.8732 - val_loss: 8.1797 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.0629 - accuracy: 0.8592 - val_loss: 8.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.9961 - accuracy: 0.8873 - val_loss: 8.1526 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.9366 - accuracy: 0.9296 - val_loss: 8.1834 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.8886 - accuracy: 0.9296 - val_loss: 8.2896 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8330 - accuracy: 0.9577 - val_loss: 8.3129 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.7880 - accuracy: 0.9718 - val_loss: 8.2627 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.7495 - accuracy: 0.9577 - val_loss: 8.2169 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.7048 - accuracy: 0.9718 - val_loss: 8.2662 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6651 - accuracy: 0.9718 - val_loss: 8.3502 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.6183 - accuracy: 0.9718 - val_loss: 8.4315 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.6074 - accuracy: 0.9577 - val_loss: 8.5195 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5972 - accuracy: 0.9577 - val_loss: 8.5560 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5637 - accuracy: 0.9859 - val_loss: 8.5419 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.5329 - accuracy: 0.9718 - val_loss: 8.4895 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.5083 - accuracy: 1.0000 - val_loss: 8.5063 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4916 - accuracy: 0.9718 - val_loss: 8.6292 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4704 - accuracy: 0.9859 - val_loss: 8.6850 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.4472 - accuracy: 0.9859 - val_loss: 8.6827 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.4132 - accuracy: 0.9859 - val_loss: 8.6627 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4001 - accuracy: 1.0000 - val_loss: 8.6609 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.3783 - accuracy: 1.0000 - val_loss: 8.6823 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.3684 - accuracy: 0.9859 - val_loss: 8.7012 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.3505 - accuracy: 0.9859 - val_loss: 8.7494 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.3263 - accuracy: 1.0000 - val_loss: 8.8074 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.3217 - accuracy: 1.0000 - val_loss: 8.8391 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.3165 - accuracy: 1.0000 - val_loss: 8.9033 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 8.9601 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.2868 - accuracy: 1.0000 - val_loss: 8.9677 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 8.9564 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.2675 - accuracy: 1.0000 - val_loss: 8.9412 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.2563 - accuracy: 1.0000 - val_loss: 8.9409 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.2392 - accuracy: 1.0000 - val_loss: 8.9547 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.2384 - accuracy: 1.0000 - val_loss: 8.9703 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.2304 - accuracy: 1.0000 - val_loss: 8.9832 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.2257 - accuracy: 1.0000 - val_loss: 9.0007 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.2140 - accuracy: 1.0000 - val_loss: 9.0296 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 9.0649 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 9.0920 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1903 - accuracy: 1.0000 - val_loss: 9.1061 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 9.1200 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 9.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1753 - accuracy: 1.0000 - val_loss: 9.1524 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 9.1686 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1646 - accuracy: 1.0000 - val_loss: 9.1876 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1614 - accuracy: 1.0000 - val_loss: 9.2005 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.1593 - accuracy: 1.0000 - val_loss: 9.2189 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 9.2377 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 0.1471 - accuracy: 1.0000 - val_loss: 9.2463 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 0.1395 - accuracy: 1.0000 - val_loss: 9.2688 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 9.2830 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 0.1392 - accuracy: 1.0000 - val_loss: 9.2912 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 9.2998 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 9.3061 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 9.3032 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 9.2986 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 9.3070 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 9.3298 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 9.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 9.3693 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.1159 - accuracy: 1.0000 - val_loss: 9.3706 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 9.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 9.3709 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 9.3881 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 9.4116 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 9.4343 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 9.4470 - val_accuracy: 0.0000e+00\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 8s 693ms/step - loss: 4.7014 - accuracy: 0.0141 - val_loss: 4.7030 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 4.6974 - accuracy: 0.0282 - val_loss: 4.7061 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 4.6941 - accuracy: 0.0563 - val_loss: 4.7099 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.6900 - accuracy: 0.0423 - val_loss: 4.7149 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 4.6851 - accuracy: 0.0282 - val_loss: 4.7220 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.6784 - accuracy: 0.0282 - val_loss: 4.7335 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.6678 - accuracy: 0.0282 - val_loss: 4.7523 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.6517 - accuracy: 0.0282 - val_loss: 4.7848 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 4.6250 - accuracy: 0.0282 - val_loss: 4.8491 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.5774 - accuracy: 0.0282 - val_loss: 4.9953 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.5069 - accuracy: 0.0282 - val_loss: 5.3339 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.4278 - accuracy: 0.0282 - val_loss: 5.9060 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.3959 - accuracy: 0.0282 - val_loss: 6.3380 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.3776 - accuracy: 0.0282 - val_loss: 6.4927 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.3519 - accuracy: 0.0282 - val_loss: 6.5249 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.3264 - accuracy: 0.0282 - val_loss: 6.5486 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 4.3135 - accuracy: 0.0282 - val_loss: 6.6133 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 4.3017 - accuracy: 0.0282 - val_loss: 6.6910 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.2993 - accuracy: 0.0000e+00 - val_loss: 6.7975 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.2942 - accuracy: 0.0141 - val_loss: 6.9134 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 4.2887 - accuracy: 0.0141 - val_loss: 7.0128 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.2869 - accuracy: 0.0282 - val_loss: 7.1183 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 4.2882 - accuracy: 0.0141 - val_loss: 7.2439 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.2909 - accuracy: 0.0141 - val_loss: 7.3340 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2879 - accuracy: 0.0141 - val_loss: 7.3943 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2880 - accuracy: 0.0141 - val_loss: 7.4345 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.2836 - accuracy: 0.0141 - val_loss: 7.4884 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2820 - accuracy: 0.0141 - val_loss: 7.5341 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 4.2740 - accuracy: 0.0141 - val_loss: 7.5700 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 4.2727 - accuracy: 0.0282 - val_loss: 7.6217 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 4.2709 - accuracy: 0.0282 - val_loss: 7.6989 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 4.2694 - accuracy: 0.0282 - val_loss: 7.7576 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 4.2674 - accuracy: 0.0282 - val_loss: 7.8061 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 145ms/step - loss: 4.2688 - accuracy: 0.0282 - val_loss: 7.8278 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 4.2689 - accuracy: 0.0282 - val_loss: 7.8410 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 4.2677 - accuracy: 0.0282 - val_loss: 7.8351 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 4.2652 - accuracy: 0.0282 - val_loss: 7.7144 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 4.2633 - accuracy: 0.0282 - val_loss: 7.5392 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 122ms/step - loss: 4.2592 - accuracy: 0.0282 - val_loss: 7.4092 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 4.2582 - accuracy: 0.0282 - val_loss: 7.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 4.2572 - accuracy: 0.0282 - val_loss: 7.2830 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 4.2540 - accuracy: 0.0282 - val_loss: 7.2716 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2535 - accuracy: 0.0282 - val_loss: 7.3131 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2529 - accuracy: 0.0282 - val_loss: 7.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.2501 - accuracy: 0.0282 - val_loss: 7.4030 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 4.2492 - accuracy: 0.0282 - val_loss: 7.4207 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.2459 - accuracy: 0.0282 - val_loss: 7.4820 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.2453 - accuracy: 0.0282 - val_loss: 7.4878 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 4.2434 - accuracy: 0.0282 - val_loss: 7.5349 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 4.2398 - accuracy: 0.0282 - val_loss: 7.6375 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2369 - accuracy: 0.0282 - val_loss: 7.6720 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 4.2319 - accuracy: 0.0282 - val_loss: 7.6917 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.2276 - accuracy: 0.0282 - val_loss: 7.7705 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 4.2235 - accuracy: 0.0282 - val_loss: 7.7965 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 4.2156 - accuracy: 0.0282 - val_loss: 7.8328 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2103 - accuracy: 0.0282 - val_loss: 7.8830 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.2042 - accuracy: 0.0282 - val_loss: 7.9063 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.1880 - accuracy: 0.0423 - val_loss: 7.9609 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.1696 - accuracy: 0.0423 - val_loss: 8.0836 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.1447 - accuracy: 0.0423 - val_loss: 8.0734 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 4.1131 - accuracy: 0.0423 - val_loss: 8.0472 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 4.0778 - accuracy: 0.0423 - val_loss: 7.8797 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.0366 - accuracy: 0.0423 - val_loss: 7.8297 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.9872 - accuracy: 0.0986 - val_loss: 8.3392 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 3.9212 - accuracy: 0.0423 - val_loss: 8.8037 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.8645 - accuracy: 0.0845 - val_loss: 8.8826 - val_accuracy: 0.0208\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.7899 - accuracy: 0.1127 - val_loss: 8.8621 - val_accuracy: 0.0417\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.7188 - accuracy: 0.0986 - val_loss: 9.1466 - val_accuracy: 0.0208\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 3.6270 - accuracy: 0.0845 - val_loss: 9.1343 - val_accuracy: 0.0208\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.5564 - accuracy: 0.1408 - val_loss: 8.7227 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 3.4642 - accuracy: 0.1268 - val_loss: 9.7236 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.4530 - accuracy: 0.1127 - val_loss: 8.2686 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 3.3991 - accuracy: 0.1127 - val_loss: 9.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.3575 - accuracy: 0.1127 - val_loss: 8.8074 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 3.3120 - accuracy: 0.1549 - val_loss: 8.8371 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.1667 - accuracy: 0.1549 - val_loss: 9.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.1776 - accuracy: 0.1690 - val_loss: 8.7929 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 3.0824 - accuracy: 0.1690 - val_loss: 9.2090 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.9961 - accuracy: 0.2113 - val_loss: 8.7865 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.9453 - accuracy: 0.2394 - val_loss: 9.1379 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.8358 - accuracy: 0.2394 - val_loss: 8.9314 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.8242 - accuracy: 0.2254 - val_loss: 9.0891 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.7248 - accuracy: 0.3239 - val_loss: 9.2379 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 2.6693 - accuracy: 0.2958 - val_loss: 9.0262 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 2.6289 - accuracy: 0.3380 - val_loss: 9.6179 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 2.5364 - accuracy: 0.3521 - val_loss: 9.3081 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 2.5259 - accuracy: 0.3380 - val_loss: 9.7066 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 2.4549 - accuracy: 0.4366 - val_loss: 9.6495 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.3898 - accuracy: 0.3944 - val_loss: 9.3269 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 2.3487 - accuracy: 0.4366 - val_loss: 9.5982 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 2.3584 - accuracy: 0.4225 - val_loss: 9.2732 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 2.2563 - accuracy: 0.4648 - val_loss: 9.2267 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.2492 - accuracy: 0.4648 - val_loss: 9.6018 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 2.1751 - accuracy: 0.4648 - val_loss: 9.5153 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 2.1306 - accuracy: 0.5352 - val_loss: 9.5494 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 2.0738 - accuracy: 0.5352 - val_loss: 10.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 150ms/step - loss: 2.0647 - accuracy: 0.5352 - val_loss: 9.8286 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 2.0048 - accuracy: 0.5352 - val_loss: 10.0219 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 1.9829 - accuracy: 0.5211 - val_loss: 9.9553 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 1.9610 - accuracy: 0.4930 - val_loss: 9.8968 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_first_model = first_history.history['val_loss'][-1]\n",
        "val_loss_second_model = second_history.history['val_loss'][-1]\n",
        "\n",
        "print(f\"Validation Loss - First Model: {val_loss_first_model}\")\n",
        "print(f\"Validation Loss - Second Model: {val_loss_second_model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffOqwHUTcadB",
        "outputId": "c2cd1c1d-74c2-483d-a3d6-73b9563f2360"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss - First Model: 9.446959495544434\n",
            "Validation Loss - Second Model: 9.896809577941895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose First Model"
      ],
      "metadata": {
        "id": "WjcQzWRad6OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_model.save(\"first_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB7drpLCdw2x",
        "outputId": "95e6ae3d-7b23-463b-f1f1-0736adef8206"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the previously saved model\n",
        "model =  tf.keras.models.load_model('first_model.h5')\n",
        "\n",
        "def predict_next_words(model, tokenizer, text, num_words=1):\n",
        "    for _ in range(num_words):\n",
        "\n",
        "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=5, padding='pre')\n",
        "\n",
        "\n",
        "        predicted_probs = model.predict(sequence, verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1)\n",
        "\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "\n",
        "        text += \" \" + output_word\n",
        "\n",
        "    return ' '.join(text.split(' ')[-num_words:])\n",
        "\n",
        "\n",
        "# Ask the user for input\n",
        "user_input = input(\"Input 5 Shona Words: \")\n",
        "\n",
        "\n",
        "predicted_words = predict_next_words(model, tokenizer, user_input, num_words=3)\n",
        "print(f\"The next words might be: {predicted_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjyFk8wsc710",
        "outputId": "a3d79865-674c-4bd5-a552-4a508c936e72"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 5 Shona Words: ndoda iwewe wega mwana wamambo\n",
            "The next words might be: ndaitopedza nguva nguva\n"
          ]
        }
      ]
    }
  ]
}